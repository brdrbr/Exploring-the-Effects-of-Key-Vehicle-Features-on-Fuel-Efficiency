# -*- coding: utf-8 -*-
"""Linear Regression ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rk2KzPdQQqN60aLX9Yk00pb_cilHDiHn

### Imports
"""

# Do NOT run unless coding in Colab
# Connect to Google Drive
# Make sure Auto.csv is save in /drive/MyDrive/Colab Notebooks/
from google.colab import drive
drive.mount('/drive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# Import libraries.
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.api import OLS
from sklearn.linear_model import LinearRegression

# Libraries for visualization
import matplotlib.pyplot as plt  # For plotting
import seaborn as sns  # For attractive and informative statistical graphics

sns.set_style('whitegrid')  # Set the style of seaborn plots to 'whitegrid'

# This command makes sure that plots are displayed inline in the Jupyter Notebook.
# %matplotlib inline

"""### Load Data"""

# Load data file

# if importing data from Google Drive
Auto = pd.read_csv('/drive/MyDrive/Colab Notebooks/Auto.csv')

# otherwise
# Auto = pd.read_csv('Auto.csv')

"""### Check Data"""

# Check head.
Auto.head()

"""### Feature Selection

"""

# Save a copy of the dataset with the 'name' column removed. We will not be using the ‘name’ variable.
# this will be our "original data"
Auto2 = Auto.drop('name', axis=1)

# Check to make sure column was dropped.
Auto2.head()

Auto2["year"].value_counts()

# create a copy of Auto2
data = Auto2.copy()

"""### Check Data again

"""

# check data types and if there are any missing values
data.info()

data.describe()

# Plot boxplot for each variable and check for outliers.
for column in data:
    plt.figure()
    data.boxplot([column])

"""### Data Cleaning

Q: should we remove outliers - feel like we might be removing some important relationships especially since the dataset is well constructed?


Q: how can we visualize the data if there are multiple features?
"""

# define a function to perform capping on a column

def capping(variable,data):

  # calculate IQR = 3rd quantile - 1st quantile
  IQR = data[variable].quantile([0.25,0.75]).values[1] - data[variable].quantile([0.25,0.75]).values[0]

  # calculate upper and lower bound
  upper_bound = data[variable].quantile([0.25,0.75]).values[1] + 1.5*IQR
  lower_bound = data[variable].quantile([0.25,0.75]).values[0] - 1.5*IQR

  # replace the values above upper bound with upper bound value
  data.loc[data[variable] > upper_bound, variable] = upper_bound

  # replace the values below lower bound with lower bound value
  data.loc[data[variable] < lower_bound, variable] = lower_bound

  return data

# perform capping on horsepower and acceleration
capping('horsepower',data)
capping('acceleration',data)

# Plot boxplot again for each variable and check for outliers
for column in data:
    plt.figure()
    data.boxplot([column])

"""### Descriptive Statistics for cleaned data

"""

data.describe()

# Displacement historgram using matplotlib

plt.hist(x='displacement', data=data, bins=15)
plt.title ("Displacement histogram")

# Horsepower historgram using matplotlib

plt.hist(x='horsepower', data=data, bins=15)
plt.title ("Horsepower histogram")

# Weight historgram using matplotlib
plt.hist(x='weight', data=data, bins=15)
plt.title ("Weight histogram")

# Acceleration historgram using matplotlib
plt.hist(x='acceleration', data=data, bins=15)
plt.title ("Acceleration histogram")
# Nearly normal!!

"""# USE THIS: Linear Regression without one hot encoding ✅

"""

# sklearn libraries for preprocessing, model selection, and metrics
from sklearn.preprocessing import StandardScaler  # To standardize features
from sklearn.linear_model import LinearRegression  # Linear regression model
from sklearn.model_selection import train_test_split  # To split the data into training and test sets
from sklearn.model_selection import KFold  # For K-fold cross-validation
from sklearn.metrics import make_scorer, confusion_matrix  # For creating custom metrics and confusion matrices
from sklearn.model_selection import learning_curve  # To generate a learning curve

# Commented out IPython magic to ensure Python compatibility.
# Libraries for visualization
import matplotlib.pyplot as plt  # For plotting
import seaborn as sns  # For attractive and informative statistical graphics

sns.set_style('whitegrid')  # Set the style of seaborn plots to 'whitegrid'

# This command makes sure that plots are displayed inline in the Jupyter Notebook.
# %matplotlib inline

# Split dataset into features and target.
X = data.drop(['mpg'],axis=1)
y = data['mpg']

# Split dataset into training and test sets.
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)

# add a constant term for intercept
X_const = sm.add_constant(X_train)

# Scale the feature data.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Set up the environment to ignore warnings.
import warnings
warnings.filterwarnings("ignore")

"""## Summary for Linear Regression without one-hot"""

# Create a linear regression model and train it with the training data.
model = sm.OLS(y_train, X_const)

# Get the result of the model
result = model.fit()

# Print the model summary and accuracy
print(result.summary(xname=['const', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']))

from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline

# adjusted R-squared
# 1 - ( 1-model.score(X, y) ) * ( len(y) - 1 ) / ( len(y) - X.shape[1] - 1 )

# Perform hyperparameter tuning to find the best hyperparameters for the linear regression model.
from sklearn.model_selection import cross_val_score

# k-fold Cross-validation (using all the 7 variables)
# we cannot implement cross validation using statsmode
# so to get cross validation score, we switch to sklearn's linear regression model
# fit_intercept = True by default so no need to add constant term
lm = LinearRegression()

# fit skleanr linear regression on training set
lm.fit(X_train, y_train)

# used trained sklearn linear regression model "lm" to predict mpg for testing data
predictions = lm.predict(X_test)

# get cross validation score of linear regression model
R2 = cross_val_score(lm, X_train, y_train, scoring='r2', cv=10) # 10-fold cross validation

print("Cross-validation results using R2: \n%0.3f accuracy with a standard deviation of %0.3f" % (R2.mean(), R2.std()))

# since we performed multi-linear reegression, we should assess model accuracy using adjust r-squared

# calculate adj r2
n = len(X_train)
p = len(X.columns)
adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1))

# use adjusted R2 as cross validation score
print("Cross-validation results using adjusted R2: \n%0.3f accuracy with a standard deviation of %0.3f" % (adj_R2.mean(), adj_R2.std()))

from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import r2_score

# Define the parameter grid
param_grid = {'alpha': [0.1, 1, 10, 100]}

# Create a Ridge regression model
ridge = Ridge()

# Use GridSearchCV to perform grid search with cross-validation
grid_search = GridSearchCV(ridge, param_grid, scoring='r2', cv=5)
grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_alpha = grid_search.best_params_['alpha']

# Train the model with the best hyperparameters
best_ridge_model = Ridge(alpha=best_alpha)
best_ridge_model.fit(X_train, y_train)

# Evaluate the model on the validation set
y_val_pred = best_ridge_model.predict(X_test)
# mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

# calculate adj r2
n = len(X_train)
p = len(X.columns)
adj_r2 = 1- ((1-r2) * (n-1)/(n-p-1))

print(f"Best alpha: {best_alpha}")
print(f"R-squared on validation set: {r2}")
print(f"Adjusted R-squared on validation set: {adj_r2}")

"""# Linear Regression with one hot encoding

"""

# create a copy of Auto2
Auto3 = Auto2.copy()

# Convert cylinders, year, and origin to factors as they are discrete variables.
Auto3['cylinders'] = Auto3['cylinders'].astype("category")
Auto3['year'] = Auto3['year'].astype("category")
Auto3['origin'] = Auto3['origin'].astype("category")

# Check data types to ensure conversion was successful.
Auto3.dtypes

"""### Feature Engineering - Part 1"""

# After one hot encoding, there will be 5 coefficients for cylinders, 13 for year, and 3 for origin.
# As such, we will group the years into decades to cut down on the number of coefficients.
# This will simplify result interpretation.

Auto3['year'].replace(71, 70, inplace=True)
Auto3['year'].replace(72, 70, inplace=True)
Auto3['year'].replace(73, 70, inplace=True)
Auto3['year'].replace(74, 70, inplace=True)
Auto3['year'].replace(75, 70, inplace=True)
Auto3['year'].replace(76, 70, inplace=True)
Auto3['year'].replace(77, 70, inplace=True)
Auto3['year'].replace(78, 70, inplace=True)
Auto3['year'].replace(79, 70, inplace=True)
Auto3['year'].replace(81, 80, inplace=True)
Auto3['year'].replace(82, 80, inplace=True)

# Check to make sure conversion was successful.
Auto3.head(10)

# One hot encode categorical variables.
# Create a list of categorical features.
# Iterate through the list and one hot encode them.
# This will help to represent categorical variables as numerical values in the regression models.

# Create list of categorical features.
categorical_features = ['cylinders', 'year', 'origin']

# One hot encode.
for feature in categorical_features:
    onehot = pd.get_dummies(Auto3[feature], prefix=feature)
    Auto3 = Auto3.drop(feature, axis=1)
    Auto3 = Auto3.join(onehot)

# Create copie of dataframe after one-hot encoding.
# Auto3_reg will be used for linear and logistic regression and further feature engineering.
# Auto4_cluster will be used for clustering and multinomial regression.
Auto3_reg = Auto3.copy()
Auto4_cluster = Auto2.copy()

Auto3.head()

# Split dataset into features and target.
X = Auto3_reg.drop(['mpg'],axis=1)
y = Auto3_reg['mpg']

# Split dataset into training and test sets.
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)

# Scale the feature data.
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# only scale the non-hot encoded columns
# col_to_scale = ['displacement','horsepower','weight','acceleration']

# X_train = np.concatenate((scaler.fit_transform(X_train[col_to_scale]),X_train.iloc[:, 4:].values), axis = 1)
# X_test = np.concatenate((scaler.fit_transform(X_test[col_to_scale]),X_test.iloc[:, 4:].values), axis = 1)

# Set up the environment to ignore warnings.
import warnings
warnings.filterwarnings("ignore")

# Create a linear regression model and train it with the training data.
model = sm.OLS(y_train, X_train)
result = model.fit()

X_train_const = sm.add_constant(X_train)

# Create a linear regression model and train it with the training data.
model = sm.OLS(y_train, X_train_const)
result = model.fit()

print(result.summary(xname=['const',
                            'displacement','horsepower','weight','acceleration',
                            'cylinders_3','cylinders_4','cylinders_5','cylinders_6','cylinders_8',
                            'year_70','year_80',
                            'origin_1','origin_2','origin_3']))

# Perform hyperparameter tuning to find the best hyperparameters for the linear regression model.

# k-fold Cross-validation
lm = LinearRegression()
R2 = cross_val_score(lm, X_train, y_train, scoring='r2', cv=10) #default 5-fold cross validation

# calculate adj r2
n = len(X_train)
p = len(X.columns)
adj_R2 = 1- ((1-R2) * (n-1)/(n-p-1))
print("Using R2: %0.3f accuracy with a standard deviation of %0.3f" % (R2.mean(), R2.std()))
print("Using Adjusted R2: %0.3f accuracy with a standard deviation of %0.3f" % (adj_R2.mean(), adj_R2.std()))

from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import r2_score

# Define the parameter grid
param_grid = {'alpha': [0.1, 1, 10, 100]}

# Create a Ridge regression model
ridge = Ridge()

# Use GridSearchCV to perform grid search with cross-validation
grid_search = GridSearchCV(ridge, param_grid, scoring='r2', cv=5)
grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_alpha = grid_search.best_params_['alpha']

# Train the model with the best hyperparameters
best_ridge_model = Ridge(alpha=best_alpha)
best_ridge_model.fit(X_train, y_train)

# Evaluate the model on the validation set
y_val_pred = best_ridge_model.predict(X_test)
#mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

# calculate adj r2
n = len(X_train)
p = len(X.columns)
adj_r2 = 1- ((1-r2) * (n-1)/(n-p-1))

print(f"Best alpha: {best_alpha}")
print(f"R-squared on validation set: {r2}")
print(f"Adjusted R-squared on validation set: {adj_r2}")